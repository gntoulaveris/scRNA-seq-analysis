---
title: "Single Cell RNA seq analysis (Dataset 1)"
author: "Grigoris Ntoulaveris"
date: "`r Sys.Date()`"
output: html_document
---


# Single Cell RNA sequence data analysis

The following is a markdown file of the single cell RNA seq analysis. A total of 5 synthetically generated datasets were analyzed. Each dataset provided the gene expression profiles (200 Genes) of 200 cells in .csv format. The datasets were read and analyzed individually, as they were considered to be from different samples or experiments.
 \
 \
To replicate the code the following packages in comment sections need to be installed and loaded first.


```{r}

#install.packages("Seurat")
#install.packages("tidyverse")
#install.packages("reshape2")
#install.packages("mclust")
#install.packages('installr')
#install.packages("rtools")
#install.packages("dplyr")
#install.packages("ggplot2")
#install.packages("Matrix")
#install.packages("factoextra")
#install.packages("knitr")
#install.packages("GGally")
#install.packages("viridis")
#install.packages("hrbrthemes")

```


```{r}
library(rlang)
library(htmltools)
library(Seurat)
library(dplyr)
library(ggplot2)
library(knitr)
library(utils)
library(reshape2)
library(mclust, quietly = TRUE)
library(Matrix)
library(installr)
library(factoextra)
library(knitr)
library(tidyr)
library(hrbrthemes)
library(GGally)
library(viridis)

```

## Dataset 1

### Data exploration


```{r}

datasets_path <- "Assignment_3_2023_datasets.zip"

data_1 <- read.csv(unz(datasets_path, "dataset1.csv"), sep=",")

print(head(data_1))

```

```{r}

print(dim(data_1))

```

```{r}
summary(data_1)
```




```{r}
melted_data_1 <- melt(data_1, value.name = 'expression')

melted_data_1 <- melted_data_1 %>%
  rename(cells = "X", genes = "variable")

```

```{r}

# compute the library size for each cell
library_size_1 <- melted_data_1 %>%
  group_by(cells) %>%
  summarise(library_size = sum(expression))

print(library_size_1)


```



```{r}

heatmap_plot <- ggplot(melted_data_1, aes(x = genes, y = cells, fill = expression)) +
  geom_tile() +
  scale_fill_gradient(low = "white", high = "red") +  
  labs(x = "Genes", y = "Cells", title = "Gene Expression Heatmap")

heatmap_plot

```





### Data preprocessing

The analysis of the datasets is performed using the R package "Seurat". It is one of the most famous packages for scRNA seq data analysis that is used in most papers.

```{r}
data_1_copy <- data.frame(data_1)

rownames(data_1_copy) <- as.character(data_1_copy[, 1])

data_1_copy <- data_1_copy[, -1]

```

```{r}

# transpose data matrix to be in correct format to be fit in a seurat object
data_1_transpose <- t(data_1_copy)


```

```{r}

#initialize the Seurat object
data1_seurat <- CreateSeuratObject(counts = data_1_transpose, project = 'Dataset 1')

str(data1_seurat)

data1_seurat


```

### Quality control

Quality control is an essential step in a scRNA seq pipeline to ensure reliability and accuracy for the data. It is performed in order to filter out low-quality cells. 

Low-quality cells can cells that express too little genes or cells that express too many genes, which can be a case of multiple cells clustered together and recognized as a single cell. The cells that have a high expression of mitochondrial genes also need to be filtered out, because high mitochondrial gene expression is observed in dying cells.


```{r}

print(data1_seurat@meta.data)


```

```{r}

# find percentage of mitochondrial genes
data1_seurat[["percent_mito"]] <- PercentageFeatureSet(data1_seurat, pattern = "^MT-")

print(data1_seurat@meta.data)


```
In the following plots the nCount_RNA corresponds to the total number of RNA molecules detected in a cell, which can be considered as a measure of the cell's RNA content or overall expression level. nFeature_RNA represents the count of unique genes or features with non-zero expression in a cell and is an indicator of the diversity of expressed genes in a cell. percent_mito corresponds to the percentage of mitochondrial genes that are expressed in a cell and a high number is indicative of cells of low-quality.

Based on the following violin plots it appears that there is an almost even distribution of cells with a high and low number of total RNA molecules. The same is true when we consider the total amount of unique genes in each cell. For both metrics the spectrum of the values is not very large though, indicating that the cells of the dataset are mostly of the same quality and expression. No mitochondrial gene expression was also detected therefore there are no dying cells in the mixture.


```{r}

VlnPlot(data1_seurat, features = c("nCount_RNA", "nFeature_RNA", "percent_mito"), ncol = 3)


```

In the following plot the total number of RNA molecules and the total number of unique genes for each cell are plotted together, to ensure that the previous visualization is not misleading in terms of cell quality. Good quality cells usually have a high value in both metrics. If many cells are clustered towards the bottom right of the plot it would mean that only a few number of unique genes were detected and those are sequenced continuously providing a misleading high number of transcripts. If many cells are clustered towards the top left of the plot it would mean that the sequencer had discovered many unique genes but they wouldn't be deeply sequenced enough to provide meaningful reasults.

As it stands most of the cells seem to be of good quality, however there is need for removal of a small number of low-quality cells.



```{r}

FeatureScatter(data1_seurat, feature1 = "nCount_RNA", feature2 = "nFeature_RNA") +
  geom_smooth(method = 'lm')

```

### Filtering 

In the filtering step low-quality cells are removed from the dataset, based on the results of the quality control. 


```{r}

data1_seurat <- subset(data1_seurat, subset = nFeature_RNA > 160 & nFeature_RNA < 1000 & 
                          percent_mito < 5)

data1_seurat

```

### Data Normalization

In order to be able to compare the levels of expression across multiple cells the data need to be normalized. The gene expression measurements for each cell is divided by the total expression of all cells, is then multiplied by a scaling factor. The result is also transformed into log space.


```{r}

data1_seurat <- NormalizeData(data1_seurat)

str(data1_seurat)

```

### High variable genes identification

The 10 most high variable genes were identified next. The intuition behind this step was to focus on the subset of genes that exhibit the greatest variation across cells. These genes are more likely to capture biologically relevant differences and can help prioritize the genes for downstream analysis.

It appears that all 200 genes are highly variable. The top 10 most high variable genes are presented in the scatter plot below.

```{r}

# find all high variable genes
data1_seurat <- FindVariableFeatures(data1_seurat, selection.method = "vst", nfeatures = 2000)

# find the top 10 high variable genes
top10_genes <- head(VariableFeatures(data1_seurat), 10)


```

```{r}

plot_variable_genes <- VariableFeaturePlot(data1_seurat)
LabelPoints(plot = plot_variable_genes, points = top10_genes, repel = TRUE)


```

### Data Scaling

This step is performed to remove unwanted variations in the data, that occur because of technical issues (eg batch effect) or biological issues (eg difference state of the cell cycle between some cells). These variations need to be removed so that the cells won't cluster together based on them, but rather based on biological similarity and effect.


```{r}

all_genes <- rownames(data1_seurat)
data1_seurat <- ScaleData(data1_seurat, features = all_genes)


```

### Dimensionality reduction

Dimensionality reduction of the expression matrix is performed to identify the sources of heterogeneity and visualize the high-dimensional dataset. It is going to be performed three different times with three different methods. Those methods are PCA, tsne, UMAP.

#### PCA


The features (genes) listed in each PC heatmap are the ones that capture the heterogeneity of the data.

```{r}

data1_seurat <- RunPCA(data1_seurat, features = VariableFeatures(object = data1_seurat))

# visualize PCA results
print(data1_seurat[["pca"]], dims = 1:5, nfeatures = 5) # for top 5 PCs
DimHeatmap(data1_seurat, dims = 1:9, cells = 197, balanced = TRUE)

```

In order to determine the number of principal components that will be used the scree plot will utilized.  The scree plot displays the eigenvalues (variance explained) of each principal component. The plot shows a decreasing curve, and the point where the curve starts to level off indicates the number of dimensions that capture most of the variation in the data. We will look for the "elbow" in the scree plot where adding more dimensions does not contribute significantly to the explained variance.

Based on the scree plot below the first 2 PC's could be chosen or perhaps more around 15-16. After them the percentage of the variance explained doesn't change much. A lower number of PC's could have been chosen, however a lower number of PC's could have had negative effects on the rest of the downstream analysis. 

```{r}

ElbowPlot(data1_seurat)


```

That being said, since the elbow plot can be interpreted subjectively, below a more quantitative approach is used to calculate where the PC's elbow happens. Two metrics will be calculated for that and their minimum value will be chosen:
1. The point where the principal components only contribute 5% of standard deviation and the principal components cumulatively contribute 90% of the standard deviation.
2. The point where the percent change in variation between the consecutive PCs is less than 0.1%.

Based on the following, the first 2 PC's will be used for dimensionality reduction.

```{r}

# 1st metric

# determine percentage of variation associated with each PC
pct <- data1_seurat[["pca"]]@stdev / sum(data1_seurat[["pca"]]@stdev) * 100

# calculate cumulative percents for each PC
cum_pct <- cumsum(pct)

# determine which PC exhibits cumulative percent greater than 90% and % variation associated with the PC as less than 5
metric1 <- which(cum_pct > 90 & pct < 5)[1]

metric1


```
```{r}

# 2nd metric

# determine the difference between variation of PC and subsequent PC
metric2 <- sort(which((pct[1:length(pct) - 1] - pct[2:length(pct)]) > 0.1), decreasing = T)[1] + 1

# last point where change of % of variation is more than 0.1%.
metric2



```

```{r}

# Minimum of the two calculation
pcs <- min(metric1, metric2)

pcs


```
```{r}

# Create a dataframe with values
plot_df <- data.frame(pct = pct, 
           cumu = cum_pct, 
           rank = 1:length(pct))

# Elbow plot to visualize 
  ggplot(plot_df, aes(cum_pct, pct, label = rank, color = rank > pcs)) + 
  geom_text() + 
  geom_vline(xintercept = 90, color = "grey") + 
  geom_hline(yintercept = min(pct[pct > 5]), color = "grey") +
  theme_bw() +
  labs(x = "Cumulative Variance (%)", y = "Variance Explained (%)", 
       title = "Rank of PC's from PCA according to their explained variance")


```

The following plot shows the projections of the first two PC's.


```{r}

DimPlot(data1_seurat, reduction="pca")



```


### Clustering

#### Clustering with PCA
The package "mclust" is utilized to cluster the data based on Gaussian Mixture Models. It uses Mclust to find the optimal model using the BIC criterion.


```{r}

# select the first 2 PC's
data1_seurat <- ProjectDim(data1_seurat, reduction = "pca", dims = 1:2)

# extract the PCA cell embeddings
pca_embeddings <- as.matrix(data1_seurat@reductions$pca@cell.embeddings)


```



```{r}

# perform GMM clustering and choose best model according to the BIC criterion
gmm_model <- Mclust(pca_embeddings[ ,1:2], G = 1:10)
cluster_ids <- gmm_model$classification

# assign the cluster identities to the Seurat object
Idents(data1_seurat) <- as.character(cluster_ids)

data1_seurat$cluster_label <- Idents(data1_seurat)


```

```{r}
data1_seurat@meta.data

```

```{r}

# Visualize clusters with DimPlot
DimPlot(data1_seurat, group.by = "cluster_label") +
  ggtitle("Clustered Cells")


```

```{r}

plot(gmm_model)

```

```{r}

summary(gmm_model)


```
```{r}

# display the covariance matrices for each cluster
gmm_model$parameters$variance$sigma



```

```{r}

# Perform discriminant analysis to obtain posterior probabilities
#gmm_da <- MclustDA(pca_embeddings[, 1:2], gmm_model$classification, G = 1:10)

# Get the posterior probabilities for each cell
#posterior_probs <- gmm_da$posterior


```



```{r}

fviz_mclust_bic(gmm_model)



```

```{r}

fviz_cluster(gmm_model)



```

```{r}
fviz_mclust(gmm_model, what = c("classification"), geom = "point")

```



```{r}

fviz_mclust(gmm_model, 'uncertainty')


```



```{r}

# Create a dataframe with cell IDs, cluster labels, and posterior probabilities
posterior_data <- data.frame(
  cell_id = rownames(pca_embeddings),
  cluster_label = gmm_model$classification,
  posterior_prob = gmm_model$z
)

posterior_data_long <- posterior_data %>%
  pivot_longer(cols = starts_with("posterior_prob"),
               names_to = "cluster",
               values_to = "posterior_prob")

cluster_means <- gmm_model$parameters$mean
cluster_covariances <- gmm_model$parameters$variance$sigma
cluster_covariances_df <- as.data.frame(cluster_covariances)

cluster_covariances


```

```{r}

# Subset the posterior_data_long to include only the cells with the highest posterior probability for each cluster
subset_data <- posterior_data_long %>%
  group_by(cell_id) %>%
  filter(posterior_prob == max(posterior_prob))


```


```{r}


subset_data %>%
  group_by(cluster_label) %>%
  ggplot(aes(x = cell_id, y = posterior_prob, fill = as.factor(cluster_label))) +
  geom_bar(stat = "identity") +
  labs(x = "Cell ID", y = "Posterior Probability") +
  facet_wrap(~ cluster_label, ncol = 1, scales = "free_x") +
  theme_bw() +
  theme(
    axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.5, size = 8),
    panel.spacing = unit(0.5, "cm"),  # Adjust the spacing between panels
    strip.text = element_text(size = 12)  # Adjust the size of the facet labels
  )

```

```{r}


ggparcoord(posterior_data, columns = 3:ncol(posterior_data), groupColumn = "cluster_label",
           scale = "uniminmax", alphaLines = 0.5, showPoints = TRUE,
           title = "Cell Posterior Probabilities")+ 
           scale_color_viridis(discrete=FALSE) 

# Adjust the plot aesthetics and theme
theme_set(theme_minimal())



```



```{r}

# Extract the posterior probabilities from the gmm_model
posterior_probs <- gmm_model$z

# Create a heatmap of the posterior probabilities
heatmap(posterior_probs, 
        col = colorRampPalette(c("white", "blue"))(100),
        main = "Posterior Distributions",
        xlab = "Cluster",
        ylab = "Cell",
        cex.axis = 0.8,
        cex.lab = 0.8)


```


